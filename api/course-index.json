[{"title":"Prompt Engineering","description":"Learn prompt engineering techniques including system messages, few-shot examples, and structured output","slug":"ai-agents-engineering/01-foundations/02-prompt-engineering","icon":"wand","body":"# Prompt Engineering\n\nLearn prompt engineering techniques including system messages, few-shot examples, and structured output.\n\n## ğŸ¯ What You'll Learn\n\n- Craft effective system messages to control model behavior\n- Use role-based prompting for consistent outputs\n- Apply few-shot learning with example-based guidance\n- Request structured output (JSON) from LLMs\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Agent Loop","description":"Build autonomous agents that use tools iteratively to accomplish complex goals","slug":"ai-agents-engineering/01-foundations/05-agent-loop","icon":"repeat","body":"# Agent Loop\n\nLearn how to build autonomous coding agents that use tools in a loop to complete tasks. This tutorial demonstrates the core pattern behind read_file, write_file, bash)\n- Handle tool calls and results in conversation flow\n- Build interactive CLI agents with proper error handling\n\n## ğŸ“¦ Available Examples\n\n| Provider | File | Description |\n|----------|------|-------------|\n| ![Anthropic](https://img.shields.io/badge/Anthropic-191919?style=for-the-badge&logo=anthropic&logoColor=white) | [01_minimal_agent.py](https://github.com/agenticloops-ai/ai-agents-engineering/blob/main/01-foundations/05-agent-loop/01_minimal_agent.py) | Minimal agent loop (~55 lines) with human-in-the-loop confirmation |\n| ![Anthropic](https://img.shields.io/badge/Anthropic-191919?style=for-the-badge&logo=anthropic&logoColor=white) | [01_agent_loop_anthropic.py](https://github.com/agenticloops-ai/ai-agents-engineering/blob/main/01-foundations/05-agent-loop/01_agent_loop_anthropic.py) | Full agent loop using Claude Messages API |\n| ![OpenAI](https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white) | [02_agent_loop_openai.py](https://github.com/agenticloops-ai/ai-agents-engineering/blob/main/01-foundations/05-agent-loop/02_agent_loop_openai.py) | Agent loop using OpenAI Responses API |\n\n## ğŸ”‘ Key Concepts\n\n### 1. The Agent Loop Pattern\n\nThe core pattern is simple: call the LLM, execute any requested tools, feed results back, repeat until done.\n\n```mermaid\n---\nconfig:\n  look: handDrawn\n  theme: neutral\n---\nflowchart TD\n    A([\"ğŸ—£ï¸ User Task        \"]) -->|init| B[\"ğŸ§  LLM Call      \"]\n    B -->|evaluate| C{\"âš™ï¸ Tool Calls?     \"}\n    C -->|\"no tools\"| D([\"ğŸ“„ Return Response  \"])\n    C -->|\"has tools\"| E[\"ğŸ”§ Execute Tools    \"]\n    E -->|collect| F[\"ğŸ“ Append Results   \"]\n    F -->|iterate| B\n```\n\n```python\nwhile iteration < max_iterations:\n    # 1. Call the model with tools\n    response = client.messages.create(\n        model=model,\n        tools=TOOLS,\n        messages=messages,\n    )\n\n    # 2. If no tool calls, task is complete\n    if response.stop_reason == \"end_turn\":\n        return response.content[0].text\n\n    # 3. Execute tools and collect results\n    for tool_call in response.tool_calls:\n        result = execute_tool(tool_call.name, tool_call.input)\n        tool_results.append(result)\n\n    # 4. Add results to conversation and continue\n    messages.append(tool_results)\n```\n\n### 2. Tools\n\nTool definitions and execution are covered in [Tool Use](/courses/ai-agents-engineering/01-foundations/04-tool-use). This tutorial uses three tools: `read_file`, `write_file`, and `bash`.\n\n### 3. Appending Tool Results\n\n**Anthropic** - Append assistant response and tool results as messages:\n```python\nmessages.append({\"role\": \"assistant\", \"content\": response.content})\nmessages.append({\"role\": \"user\", \"content\": tool_results})\n```\n\n**OpenAI Responses API** - Pass tool outputs as `input` with `previous_response_id`:\n```python\ntool_outputs = [\n    {\n        \"type\": \"function_call_output\",\n        \"call_id\": call.call_id,\n        \"output\": json.dumps({\"result\": result}),\n    }\n    for call, result in zip(function_calls, results)\n]\nresponse = client.responses.create(\n    model=model,\n    tools=TOOLS,\n    input=tool_outputs,\n    previous_response_id=response.id,\n)\n```\n\n## ğŸ—ï¸ Code Structure\n\nBoth examples follow a consistent structure:\n\n```python\nSYSTEM_PROMPT = \"\"\"You are a coding agent...\"\"\"\n\nTOOLS = [...]  # Tool definitions\n\ndef execute_tool(name: str, tool_input: dict) -> str:\n    \"\"\"Execute a tool and return the result.\"\"\"\n    ...\n\nclass CodingAgent:\n    \"\"\"Autonomous agent that uses tools in a loop.\"\"\"\n\n    def __init__(self, model: str):\n        self.client = ...\n        self.model = model\n        self.max_iterations = 10\n\n    def run(self, task: str) -> str:\n        \"\"\"Execute the agent loop for the given task.\"\"\"\n        # Agent loop implementation\n        ...\n\ndef main() -> None:\n    \"\"\"Interactive CLI with welcome message.\"\"\"\n    agent = CodingAgent()\n\n    while True:\n        user_input = input(\"You: \")\n        if user_input.lower() in (\"exit\", \"quit\", \"q\"):\n            break\n        response = agent.run(user_input)\n        print(f\"Agent: {response}\")\n```\n\n\n## ğŸ‘‰ Next Steps\n\nOnce you've mastered the agent loop pattern:\n- Add more tools (web search, database queries, API calls)\n- Implement tool confirmation for destructive actions\n- Add memory/context management for longer conversations\n- Explore streaming responses for better UX"},{"title":"Interactive Chat","description":"Build an interactive chat loop with message history using Anthropic Claude and OpenAI GPT","slug":"ai-agents-engineering/01-foundations/03-chat","icon":"message-circle","body":"# Interactive Chat\n\nBuild an interactive chat application with conversation history management. This tutorial demonstrates how to maintain context across multiple turns and create an engaging conversational user experience.\n\n> **ğŸ“š Setup & Running:** See [SETUP.md](/courses/ai-agents-engineering/SETUP.md) for prerequisites, setup instructions, and how to run tutorials.\n\n## ğŸ¯ What You'll Learn\n\n- Implement an interactive chat loop with user input\n- Manage conversation history across multiple turns\n- Maintain context for natural multi-turn conversations\n- Track token usage and conversation statistics\n- Create rich console output for better UX\n\n## ğŸ“¦ Available Examples\n\n| Provider | File | Description |\n|----------|------|-------------|\n| ![Anthropic](https://img.shields.io/badge/Anthropic-191919?style=for-the-badge&logo=anthropic&logoColor=white) | [01_chat_anthropic.py](https://github.com/agenticloops-ai/ai-agents-engineering/blob/main/01-foundations/03-chat/01_chat_anthropic.py) | Interactive chat using Claude Messages API |\n| ![OpenAI](https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white) | [02_chat_openai.py](https://github.com/agenticloops-ai/ai-agents-engineering/blob/main/01-foundations/03-chat/02_chat_openai.py) | Interactive chat using OpenAI Responses API |\n\n## ğŸ”‘ Key Concepts\n\n### 1. Chat Loop Pattern\n\n```mermaid\n---\nconfig:\n  look: handDrawn\n  theme: neutral\n---\nflowchart TD\n    A([\"ğŸ—£ï¸ User Input      \"]) -->|append| B[\"ğŸ“ Store in History \"]\n    B -->|send| C[\"ğŸ§  LLM Call       \"]\n    C -->|append| D[\"ğŸ“ Store Response   \"]\n    D -->|render| E([\"ğŸ’¬ Display Output   \"])\n    E -->|loop| A\n```\n\n### 2. Message History Management\n\nThe key to multi-turn conversations is maintaining a message history array:\n\n**Anthropic:**\n```python\nclass ChatSession:\n    def __init__(self, model: str):\n        self.client = anthropic.Anthropic()\n        self.messages: list[dict[str, str]] = []\n        self.model = model\n\n    def send_message(self, user_message: str) -> str:\n        # Add user message to history\n        self.messages.append({\"role\": \"user\", \"content\": user_message})\n\n        # Send entire history to API\n        response = self.client.messages.create(\n            model=self.model,\n            messages=self.messages,\n        )\n\n        # Extract response\n        assistant_message = response.content[0].text\n\n        # Add assistant response to history\n        self.messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n\n        return assistant_message\n```\n\n**OpenAI:**\n```python\nclass ChatSession:\n    def __init__(self, model: str):\n        self.client = OpenAI()\n        self.messages: list[dict[str, str]] = []\n        self.model = model\n\n    def send_message(self, user_message: str) -> str:\n        # Add user message to history\n        self.messages.append({\"role\": \"user\", \"content\": user_message})\n\n        # Send entire history to API using Responses API\n        response = self.client.responses.create(\n            model=self.model,\n            input=self.messages,\n        )\n\n        # Extract response\n        assistant_message = response.output_text or \"\"\n\n        # Add assistant response to history\n        self.messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n\n        return assistant_message\n```\n\n### 3. Interactive Chat Loop\n\nCreate a continuous conversation flow:\n\n```python\ndef main() -> None:\n    console = Console()\n    chat = ChatSession(\"model-name\")\n\n    # Welcome message\n    console.print(Panel(\"Welcome to Chat!\"))\n\n    # Interactive loop\n    while True:\n        # Get user input\n        console.print(\"You: \", end=\"\")\n        user_input = input().strip()\n\n        # Exit condition\n        if user_input.lower() in [\"quit\", \"exit\", \"\"]:\n            break\n\n        # Process message\n        try:\n            response = chat.send_message(user_input)\n            console.print(f\"Assistant: {response}\")\n        except Exception as e:\n            console.print(f\"Error: {e}\")\n            break\n```\n\n### 4. Token Tracking\n\nMonitor API usage across the conversation:\n\n**Anthropic:**\n```python\ntoken_tracker = AnthropicTokenTracker()\n\n# After each API call\nresponse = self.client.messages.create(...)\ntoken_tracker.track(response.usage)\n\n# At end of session\ntoken_tracker.report()  # Shows total input/output/cost\n```\n\n**OpenAI:**\n```python\ntoken_tracker = OpenAITokenTracker()\n\n# After each API call\nresponse = self.client.responses.create(...)\ntoken_tracker.track(response.usage)\n\n# At end of session\ntoken_tracker.report()  # Shows total input/output/cost\n```\n\n## âš ï¸ Important Considerations\n\n**Context Window Limits**: As conversations grow, the message history consumes more tokens. Eventually, you'll hit the model's context window limit. Advanced techniques for handling this include:\n- Truncating old messages\n- Summarizing conversation history\n- Using sliding windows\n\n**Error Handling**: Production chat applications should handle:\n- Network errors and API failures\n- Rate limiting and retries\n- Invalid user input\n- Token limit exceeded errors\n\n**Cost Management**: Every message sends the entire conversation history. Longer conversations = higher costs per message. Monitor token usage carefully.\n\nThese strategies will be covered in future tutorials.\n\n## ğŸ‘‰ Next Steps\n\nOnce you've built interactive chat sessions, continue to:\n- **[Tool Use](/courses/ai-agents-engineering/01-foundations/04-tool-use)** - Add external capabilities to your chat agent\n- **Experiment** - Try different conversation flows and system prompts\n- **Enhance** - Add features like conversation summarization or history persistence"},{"title":"Simple LLM Call","description":"Make your first API call using Anthropic Claude, OpenAI GPT, and LiteLLM","slug":"ai-agents-engineering/01-foundations/01-simple-llm-call","icon":"zap","body":"# Simple LLM Call\n\nLearn how to make basic calls to LLM APIs. This tutorial demonstrates how to interact with different LLM providers and get a simple text response.\n\n> **ğŸ“š Setup & Running:** See [SETUP.md](/courses/ai-agents-engineering/SETUP.md) for prerequisites, setup instructions, and how to run tutorials.\n\n## ğŸ¯ What You'll Learn\n\n- Initialize and configure LLM clients for different providers\n- Make simple API calls with single prompts\n- Extract text responses from API calls\n- Use a unified interface (LiteLLM) to work with multiple providers\n\n## ğŸ“¦ Available Examples\n\n| Provider | File | Description |\n|----------|------|-------------|\n| ![Anthropic](https://img.shields.io/badge/Anthropic-191919?style=for-the-badge&logo=anthropic&logoColor=white) | [01_llm_call_anthropic.py](https://github.com/agenticloops-ai/ai-agents-engineering/blob/main/01-foundations/01-simple-llm-call/01_llm_call_anthropic.py) | Basic Claude Messages API calls |\n| ![OpenAI](https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white) | [02_llm_call_openai.py](https://github.com/agenticloops-ai/ai-agents-engineering/blob/main/01-foundations/01-simple-llm-call/02_llm_call_openai.py) | Basic OpenAI Responses API calls |\n| ![LiteLLM](https://img.shields.io/badge/LiteLLM-ED7D31?style=for-the-badge) | [03_llm_call_litellm.py](https://github.com/agenticloops-ai/ai-agents-engineering/blob/main/01-foundations/01-simple-llm-call/03_llm_call_litellm.py) | Unified interface for any provider |\n\n## ğŸ”‘ Key Concepts\n\n### 1. Simple LLM Call Flow\n\n```mermaid\n---\nconfig:\n  look: handDrawn\n  theme: neutral\n---\nflowchart LR\n    A([\"âš¡ Input Prompt\"]) -->|request| B[\"ğŸ§  LLM Call   \"]\n    B -->|response| C([\"ğŸ“„ Response Text\"])\n```\n\n### 2. LLM Client Initialization\n\nEach provider has its own client initialization:\n\n**Anthropic:**\n```python\nimport anthropic\n\nclient = anthropic.Anthropic()  # Uses ANTHROPIC_API_KEY from env\nmodel = \"claude-sonnet-4-20250514\"\n```\n\n**OpenAI:**\n```python\nfrom openai import OpenAI\n\nclient = OpenAI()  # Uses OPENAI_API_KEY from env\nmodel = \"gpt-4o\"\n```\n\n**LiteLLM:**\n```python\nfrom litellm import completion\n\n# No client needed - just call completion()\n# Uses appropriate API key based on model name\n```\n\n### 3. Making API Calls\n\n**Anthropic (Messages API):**\n```python\nresponse = client.messages.create(\n    model=\"claude-sonnet-4-20250514\",\n    temperature=0.1,\n    max_tokens=1024,\n    system=\"You are a helpful AI assistant.\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hello!\"}\n    ],\n)\ntext = response.content[0].text\n```\n\n**OpenAI (Responses API):**\n```python\nresponse = client.responses.create(\n    model=\"gpt-4o\",\n    temperature=0.1,\n    max_output_tokens=1024,\n    instructions=\"You are a helpful AI assistant.\",\n    input=\"Hello!\",\n)\ntext = response.output_text\n```\n\n**LiteLLM (Unified API):**\n```python\nresponse = completion(\n    model=\"gpt-4o\",  # Or \"claude-sonnet-4-20250514\"\n    temperature=0.1,\n    max_tokens=1024,\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n        {\"role\": \"user\", \"content\": \"Hello!\"}\n    ],\n)\ntext = response.choices[0].message.content\n```\n\n> These examples show basic (non-streaming) API calls. For streaming responses, see the [Anthropic Streaming docs](https://docs.anthropic.com/en/api/messages-streaming), [OpenAI Streaming docs](https://platform.openai.com/docs/api-reference/streaming), and [LiteLLM Streaming docs](https://docs.litellm.ai/docs/completion/stream).\n\n### 4. Key Configuration Parameters\n\n**Model**: Specifies which LLM to use (e.g., `claude-sonnet-4-20250514`, `gpt-4o`)\n\n**Temperature**: Controls randomness (0.0 = deterministic, 1.0 = creative)\n- Lower values (0.0-0.3) for factual, consistent responses\n- Higher values (0.7-1.0) for creative, varied outputs\n\n**Max Tokens**: Limits the response length\n- Anthropic/LiteLLM: `max_tokens`\n- OpenAI Responses API: `max_output_tokens`\n\n**System Prompt**: Defines the assistant's behavior and context\n- Anthropic: `system` parameter\n- OpenAI: `instructions` parameter\n- LiteLLM: System message in `messages` array\n\n> Other advanced parameters like `top_p`, `top_k`, `stop_sequences`, `presence_penalty`, `frequency_penalty`, and `seed` will be covered in future tutorials.\n\n## ğŸ—ï¸ Code Structure\n\nAll examples follow a consistent structure:\n\n```python\nclass LLMClient:\n    \"\"\"Encapsulates LLM interaction logic.\"\"\"\n\n    def __init__(self, model: str):\n        self.client = ...  # Initialize API client\n        self.model = model\n        self.system_prompt = \"...\"\n\n    def run(self, prompt: str) -> str:\n        \"\"\"Execute a single LLM call.\"\"\"\n        # 1. Make API call\n        response = self.client...\n\n        # 2. Extract and return text\n        return response_text\n\n\ndef main() -> None:\n    \"\"\"Orchestrates execution flow.\"\"\"\n    # 1. Initialize client\n    client = LLMClient(\"model-name\")\n\n    # 2. Define prompt\n    prompt = \"...\"\n\n    # 3. Get response\n    response = client.run(prompt)\n\n    # 4. Display result\n    logger.info(f\"Response: {response}\")\n```\n\n## ğŸ‘‰ Next Steps\n\nOnce you've mastered simple LLM calls, continue to:\n- **[Prompt Engineering](/courses/ai-agents-engineering/01-foundations/02-prompt-engineering)** - Learn to craft effective prompts for better responses\n- **Experiment** - Try different models, temperatures, and prompts\n- **Explore** - Modify the examples to add features like retry logic or error handling"},{"title":"Tool Use","description":"Enable LLMs to call functions and interact with external systems","slug":"ai-agents-engineering/01-foundations/04-tool-use","icon":"wrench","body":"# Tool Use\n\nLearn how to give LLMs the ability to call functions (tools) to interact with the real world. This tutorial demonstrates how to define tools, handle tool calls, and execute functions on behalf of the model.\n\n> **Setup & Running:** See [SETUP.md](/courses/ai-agents-engineering/SETUP.md) for prerequisites, setup instructions, and how to run tutorials.\n\n## ğŸ¯ What You'll Learn\n\n- Define tools with JSON Schema for LLM consumption\n- Handle the tool call loop (request -> execute -> respond)\n- Execute functions safely with guardrails\n- Work with multiple tool calls in a single response\n\n## ğŸ“¦ Available Examples\n\n| Provider | File | Description |\n|----------|------|-------------|\n| ![Anthropic](https://img.shields.io/badge/Anthropic-191919?style=for-the-badge&logo=anthropic&logoColor=white) | [01_tool_use_anthropic.py](https://github.com/agenticloops-ai/ai-agents-engineering/blob/main/01-foundations/04-tool-use/01_tool_use_anthropic.py) | Tool use with Claude Messages API |\n| ![OpenAI](https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white) | [02_tool_use_openai.py](https://github.com/agenticloops-ai/ai-agents-engineering/blob/main/01-foundations/04-tool-use/02_tool_use_openai.py) | Tool use with OpenAI Responses API |\n\n## ğŸ”‘ Key Concepts\n\n### 1. Tool Definition\n\nTools are defined using JSON Schema so the LLM understands what functions are available:\n\n**Anthropic:**\n```python\nTOOLS = [\n    {\n        \"name\": \"calculator\",\n        \"description\": \"Performs basic arithmetic operations.\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"operation\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"add\", \"subtract\", \"multiply\", \"divide\"],\n                },\n                \"a\": {\"type\": \"number\"},\n                \"b\": {\"type\": \"number\"},\n            },\n            \"required\": [\"operation\", \"a\", \"b\"],\n        },\n    },\n]\n```\n\n**OpenAI:**\n```python\nTOOLS = [\n    {\n        \"type\": \"function\",\n        \"name\": \"calculator\",\n        \"description\": \"Performs basic arithmetic operations.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"operation\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"add\", \"subtract\", \"multiply\", \"divide\"],\n                },\n                \"a\": {\"type\": \"number\"},\n                \"b\": {\"type\": \"number\"},\n            },\n            \"required\": [\"operation\", \"a\", \"b\"],\n        },\n    },\n]\n```\n\n### 2. The Tool Call Loop\n\nThe LLM doesn't execute tools directly - it requests tool calls that you execute:\n\n```\nUser Message\n    |\nLLM Response (with tool_use)\n    |\nExecute Tool -> Get Result\n    |\nSend Result Back to LLM\n    |\nLLM Response (final answer)\n```\n\n**Anthropic:**\n```python\nresponse = client.messages.create(\n    model=\"claude-sonnet-4-20250514\",\n    tools=TOOLS,\n    messages=messages,\n)\n\nif response.stop_reason == \"tool_use\":\n    for block in response.content:\n        if isinstance(block, ToolUseBlock):\n            result = execute_tool(block.name, block.input)\n            # Send result back with tool_use_id\n```\n\n**OpenAI:**\n```python\nresponse = client.responses.create(\n    model=\"gpt-4o\",\n    tools=TOOLS,\n    input=messages,\n)\n\nfor output in response.output:\n    if output.type == \"function_call\":\n        result = execute_tool(output.name, json.loads(output.arguments))\n        # Send result back with call_id\n```\n\n### 3. Tool Implementation with Guardrails\n\nAlways validate and sanitize tool inputs, especially for system-level tools:\n\n```python\nBLOCKED_COMMANDS = [\"rm\", \"sudo\", \"chmod\", \"shutdown\", \">\", \">>\"]\n\ndef run_bash(command: str, timeout: int = 30) -> dict:\n    \"\"\"Execute a bash command with safety guardrails.\"\"\"\n    # Block dangerous commands\n    for blocked in BLOCKED_COMMANDS:\n        if blocked in command.lower():\n            return {\"error\": f\"Command blocked: contains '{blocked}'\"}\n\n    result = subprocess.run(\n        command,\n        shell=True,\n        capture_output=True,\n        timeout=timeout,\n    )\n    return {\"stdout\": result.stdout, \"stderr\": result.stderr}\n```\n\n### 4. Handling Multiple Tool Calls\n\nLLMs can request multiple tool calls in a single response. Process all of them before continuing:\n\n**Anthropic:**\n```python\ntool_results = []\nfor tool_use in tool_uses:\n    result = execute_tool(tool_use.name, tool_use.input)\n    tool_results.append({\n        \"type\": \"tool_result\",\n        \"tool_use_id\": tool_use.id,\n        \"content\": json.dumps(result),\n    })\nmessages.append({\"role\": \"user\", \"content\": tool_results})\n```\n\n**OpenAI:**\n```python\n# Add function calls to messages first\nmessages.extend(response.output)\n\n# Then add results\nfor func_call in function_calls:\n    result = execute_tool(func_call.name, json.loads(func_call.arguments))\n    messages.append({\n        \"type\": \"function_call_output\",\n        \"call_id\": func_call.call_id,\n        \"output\": json.dumps(result),\n    })\n```\n\n## ğŸ§° Tools in This Tutorial\n\n| Tool | Description |\n|------|-------------|\n| `calculator` | Basic arithmetic (add, subtract, multiply, divide) |\n| `read_file` | Read file contents from the filesystem |\n| `run_bash` | Execute shell commands (with safety guardrails) |\n\n## ğŸ—ï¸ Code Structure\n\nBoth examples follow a consistent structure:\n\n```python\n# 1. Define tools as JSON Schema\nTOOLS = [...]\n\n# 2. Implement tool functions\ndef calculator(operation: str, a: float, b: float) -> dict:\n    ...\n\ndef read_file(path: str) -> dict:\n    ...\n\ndef run_bash(command: str) -> dict:\n    ...\n\n# 3. Tool execution dispatcher\nTOOL_FUNCTIONS = {\"calculator\": calculator, \"read_file\": read_file, ...}\n\ndef execute_tool(name: str, input: dict) -> Any:\n    return TOOL_FUNCTIONS[name](**input)\n\n\n# 4. Chat class with tool loop\nclass ToolUseChat:\n    def send_message(self, message: str) -> str:\n        while True:\n            response = self.client.create(tools=TOOLS, ...)\n\n            if has_tool_calls(response):\n                execute_tools_and_add_results()\n                continue\n            else:\n                return response.text\n\n\n# 5. Main orchestration\ndef main():\n    chat = ToolUseChat(model, token_tracker, console)\n    while True:\n        user_input = input()\n        response = chat.send_message(user_input)\n        print(response)\n```\n\n## ğŸ‘‰ Next Steps\n\nOnce you've mastered tool use, continue to:\n- **[Agent Loop](/courses/ai-agents-engineering/01-foundations/05-agent-loop)** - Build autonomous agents that use tools to complete tasks\n- **Experiment** - Add more tools like web search, database queries, or API calls\n- **Explore** - Implement tool choice modes (`auto`, `required`, `none`)"},{"title":"Augmented LLM","description":"The basic building block of agentic systems â€” an LLM enhanced with retrieval, tools, and memory","slug":"ai-agents-engineering/02-effective-agents/01-augmented-llm","icon":"layers","body":"# Augmented LLM\n\nThe basic building block of agentic systems is an LLM enhanced with augmentations such as retrieval, tools, and memory. Modern models can actively use these capabilities â€” generating their own search queries, selecting appropriate tools, and determining what information to retain.\n\n## ğŸ¯ What You'll Learn\n\n- Understand the augmented LLM as the foundation of all agentic patterns\n- Implement retrieval augmentation to ground responses in external knowledge\n- Connect LLMs to tools they can invoke autonomously\n- Add memory to persist context across interactions\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Prompt Chaining","description":"Break complex tasks into sequential steps where each LLM call builds on the previous output","slug":"ai-agents-engineering/02-effective-agents/02-prompt-chaining","icon":"link","body":"# Prompt Chaining\n\nBreak complex tasks into sequential steps where each LLM call builds on the previous output. Simple, debuggable, and surprisingly powerful.\n\n## ğŸ¯ What You'll Learn\n\n- Design multi-step LLM pipelines with clear handoffs\n- Pass context and results between sequential calls\n- Debug and trace execution through the chain\n- Know when chaining beats a single complex prompt\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Routing","description":"Classify incoming requests and dispatch them to specialized handlers","slug":"ai-agents-engineering/02-effective-agents/03-routing","icon":"split","body":"# Routing\n\nClassify incoming requests and dispatch them to specialized handlers. One agent decides, others execute â€” the foundation of scalable systems.\n\n## ğŸ¯ What You'll Learn\n\n- Build LLM-based classifiers to route user intent\n- Design specialized handlers for different request types\n- Implement fallback strategies for edge cases\n- Scale systems by adding new routes without rewriting core logic\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Orchestrator-Workers","description":"A central agent dynamically breaks down tasks and delegates to specialized workers","slug":"ai-agents-engineering/02-effective-agents/05-orchestrator-workers","icon":"network","body":"# Orchestrator-Workers\n\nA central agent dynamically breaks down tasks and delegates to specialized workers. The pattern behind most \"AI agent\" products you see today.\n\n## ğŸ¯ What You'll Learn\n\n- Design an orchestrator that decomposes complex tasks\n- Build specialized worker agents with focused capabilities\n- Implement dynamic task assignment and result collection\n- Handle coordination, dependencies, and failure recovery\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Parallelization","description":"Fan-out work across multiple LLM calls simultaneously, then aggregate results","slug":"ai-agents-engineering/02-effective-agents/04-parallelization","icon":"layers","body":"# Parallelization\n\nFan-out work across multiple LLM calls simultaneously, then aggregate results. Trade latency for throughput when tasks are independent.\n\n## ğŸ¯ What You'll Learn\n\n- Identify tasks that can run in parallel vs. sequentially\n- Implement fan-out/fan-in patterns with async execution\n- Aggregate and reconcile results from parallel calls\n- Handle partial failures and timeouts gracefully\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Evaluator-Optimizer","description":"One LLM generates, another critiques, and the cycle repeats until quality thresholds are met","slug":"ai-agents-engineering/02-effective-agents/06-evaluator-optimizer","icon":"refresh","body":"# Evaluator-Optimizer\n\nOne LLM generates, another critiques, and the cycle repeats until quality thresholds are met. Self-improving output without human intervention.\n\n## ğŸ¯ What You'll Learn\n\n- Implement generator-critic loops for iterative refinement\n- Design evaluation criteria and quality thresholds\n- Avoid infinite loops with termination conditions\n- Balance improvement gains against cost and latency\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Human in the Loop","description":"Build approval gates, escalation paths, and feedback mechanisms for production agents","slug":"ai-agents-engineering/02-effective-agents/07-human-in-the-loop","icon":"user-check","body":"# Human in the Loop\n\nBuild approval gates, escalation paths, and feedback mechanisms. Every production agent needs a strategy for when to ask a human.\n\n## ğŸ¯ What You'll Learn\n\n- Design approval gates for high-stakes actions\n- Implement escalation paths when agents are uncertain\n- Collect and incorporate human feedback into agent behavior\n- Balance autonomy with oversight for production safety\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Structured Output","description":"Force LLM responses into exact schemas â€” JSON mode, Pydantic models, constrained generation","slug":"ai-agents-engineering/03-advanced-techniques/01-structured-output","icon":"code","body":"# Structured Output\n\nForce LLM responses into exact schemas â€” JSON mode, Pydantic models, constrained generation. The bridge between natural language and your application code.\n\n## ğŸ¯ What You'll Learn\n\n- Use JSON mode and response schemas across providers\n- Validate LLM output with Pydantic models\n- Handle schema violations and malformed responses\n- Design schemas that models can reliably follow\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Context Management","description":"Handle the reality of finite context windows with sliding windows, summarization, and chunking","slug":"ai-agents-engineering/03-advanced-techniques/02-context-management","icon":"layers","body":"# Context Management\n\nHandle the reality of finite context windows. Sliding windows, summarization, chunking strategies, and knowing what to keep vs. what to drop.\n\n## ğŸ¯ What You'll Learn\n\n- Implement sliding window strategies for long conversations\n- Summarize older context to preserve meaning in fewer tokens\n- Chunk large documents for effective retrieval\n- Prioritize what stays in context when tokens are tight\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Memory","description":"Give agents memory that persists across sessions â€” short-term buffers, long-term stores, and vector databases","slug":"ai-agents-engineering/03-advanced-techniques/03-memory","icon":"database","body":"# Memory\n\nGive agents memory that persists across sessions. Short-term conversation buffers, long-term vector stores, and hybrid approaches.\n\n## ğŸ¯ What You'll Learn\n\n- Build short-term memory for conversation continuity\n- Implement long-term memory with vector stores\n- Design retrieval strategies for relevant memory recall\n- Combine memory types for agents that truly remember\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Prompt Caching","description":"Cache static prompt prefixes to cut latency and cost","slug":"ai-agents-engineering/03-advanced-techniques/04-prompt-caching","icon":"zap","body":"# Prompt Caching\n\nCache static prompt prefixes to cut latency and cost. Understand when caching helps, when it doesn't, and how to structure prompts for maximum reuse.\n\n## ğŸ¯ What You'll Learn\n\n- Enable prompt caching across different providers\n- Structure prompts to maximize cache hits\n- Measure cost savings and latency improvements\n- Know when caching helps vs. adds unnecessary complexity\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Multimodal","description":"Process images, audio, and files alongside text","slug":"ai-agents-engineering/03-advanced-techniques/05-multimodal","icon":"image","body":"# Multimodal\n\nProcess images, audio, and files alongside text. Build agents that can see screenshots, read documents, and work with the real-world data your users have.\n\n## ğŸ¯ What You'll Learn\n\n- Send images and screenshots to vision-capable models\n- Process audio input and generate audio output\n- Handle PDFs, documents, and file uploads\n- Build agents that work with real-world multimodal data\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"MCP (Model Context Protocol)","description":"Connect agents to external tools through a standardized protocol","slug":"ai-agents-engineering/03-advanced-techniques/06-mcp","icon":"plug","body":"# MCP (Model Context Protocol)\n\nConnect agents to external tools through a standardized protocol. Build and consume MCP servers for databases, APIs, file systems, and more.\n\n## ğŸ¯ What You'll Learn\n\n- Understand the Model Context Protocol specification\n- Consume existing MCP servers for common tools\n- Build custom MCP servers for your own APIs\n- Integrate MCP tools into your agent architecture\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"RAG Techniques","description":"Advanced retrieval patterns â€” vector search, hybrid retrieval, GraphRAG, and agentic RAG","slug":"ai-agents-engineering/03-advanced-techniques/08-rag-techniques","icon":"search","body":"# RAG Techniques\n\nMove beyond basic vector similarity search. Learn hybrid retrieval, knowledge graphs, contextual chunking, and agentic RAG patterns that handle complex, multi-hop queries.\n\n## ğŸ¯ What You'll Learn\n\n- Implement hybrid search combining keyword (BM25) and semantic retrieval\n- Use re-ranking to filter and prioritize retrieved context\n- Build GraphRAG pipelines with knowledge graphs for relationship-aware retrieval\n- Design agentic RAG where the agent decides when and what to retrieve\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Multi-Agent Systems","description":"Multiple agents collaborating on shared tasks with communication and delegation","slug":"ai-agents-engineering/03-advanced-techniques/07-multi-agent-systems","icon":"users","body":"# Multi-Agent Systems\n\nMultiple agents collaborating on shared tasks. Communication patterns, delegation, conflict resolution, and when multi-agent is (and isn't) the right call.\n\n## ğŸ¯ What You'll Learn\n\n- Design agent communication and message passing patterns\n- Implement delegation and handoff between agents\n- Handle conflicts when agents disagree\n- Know when multi-agent adds value vs. unnecessary complexity\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"No Framework","description":"The raw SDK baseline â€” pure client code with no abstractions","slug":"ai-agents-engineering/04-frameworks/01-no-framework","icon":"code","body":"# No Framework\n\nThe raw SDK baseline. Pure Anthropic/OpenAI client code with no abstractions. This is your reference implementation â€” everything else is measured against it.\n\n## ğŸ¯ What You'll Learn\n\n- Build a complete agent using only provider SDKs\n- Understand exactly what frameworks abstract away\n- Establish a baseline for comparing framework trade-offs\n- Make informed decisions about when abstraction helps\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"LangGraph","description":"Graph-based agent orchestration from LangChain","slug":"ai-agents-engineering/04-frameworks/02-langgraph","icon":"git-branch","body":"# LangGraph\n\nGraph-based agent orchestration from LangChain. Define agents as nodes and edges with built-in state management and persistence.\n\n## ğŸ¯ What You'll Learn\n\n- Model agent workflows as directed graphs\n- Use built-in state management and checkpointing\n- Implement conditional edges for dynamic routing\n- Compare graph-based approach to linear orchestration\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Pydantic AI","description":"Type-safe agent framework built on Pydantic","slug":"ai-agents-engineering/04-frameworks/03-pydantic-ai","icon":"shield","body":"# Pydantic AI\n\nType-safe agent framework built on Pydantic. Strong typing, dependency injection, and structured outputs as first-class citizens.\n\n## ğŸ¯ What You'll Learn\n\n- Define agents with Pydantic models for type safety\n- Use dependency injection for testable agent code\n- Get structured outputs validated at runtime\n- Leverage Python's type system for agent development\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Google ADK","description":"Google's Agent Development Kit with multi-agent orchestration","slug":"ai-agents-engineering/04-frameworks/04-google-adk","icon":"cpu","body":"# Google ADK\n\nGoogle's Agent Development Kit. Multi-agent orchestration with built-in tool support and Gemini integration.\n\n## ğŸ¯ What You'll Learn\n\n- Build agents using Google's ADK architecture\n- Leverage native Gemini model integration\n- Use built-in tool definitions and execution\n- Orchestrate multi-agent workflows with ADK primitives\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"AutoGen","description":"Microsoft's multi-agent conversation framework","slug":"ai-agents-engineering/04-frameworks/07-autogen","icon":"message-circle","body":"# AutoGen\n\nMicrosoft's multi-agent conversation framework. Agents communicate through structured conversations with configurable interaction patterns.\n\n## ğŸ¯ What You'll Learn\n\n- Set up multi-agent conversations with AutoGen\n- Configure interaction patterns and termination conditions\n- Use human-in-the-loop conversation flows\n- Build autonomous agent teams for complex tasks\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"AWS Strands","description":"AWS's agent SDK with native service integration","slug":"ai-agents-engineering/04-frameworks/05-aws-strands","icon":"cloud","body":"# AWS Strands\n\nAWS's agent SDK. Model-driven development with native AWS service integration and deployment tooling.\n\n## ğŸ¯ What You'll Learn\n\n- Build agents using AWS Strands architecture\n- Integrate with AWS services natively\n- Use model-driven development patterns\n- Deploy agents with AWS infrastructure tooling\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"LlamaIndex","description":"Data-centric agent framework with strong RAG primitives","slug":"ai-agents-engineering/04-frameworks/08-llamaindex","icon":"database","body":"# LlamaIndex\n\nData-centric agent framework. Strong RAG primitives, knowledge graph integration, and document-aware agents.\n\n## ğŸ¯ What You'll Learn\n\n- Build data-aware agents with LlamaIndex\n- Use built-in RAG and retrieval pipelines\n- Integrate knowledge graphs for complex reasoning\n- Create agents that work naturally with documents\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"CrewAI","description":"Role-based multi-agent collaboration framework","slug":"ai-agents-engineering/04-frameworks/06-crewai","icon":"users","body":"# CrewAI\n\nRole-based multi-agent collaboration. Define agents with roles, goals, and backstories that work together on complex tasks.\n\n## ğŸ¯ What You'll Learn\n\n- Define agents with distinct roles, goals, and backstories\n- Orchestrate crews for collaborative task completion\n- Configure agent communication and delegation patterns\n- Build multi-agent workflows with clear responsibilities\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Semantic Kernel","description":"Microsoft's AI orchestration SDK with plugin architecture","slug":"ai-agents-engineering/04-frameworks/09-semantic-kernel","icon":"puzzle","body":"# Semantic Kernel\n\nMicrosoft's AI orchestration SDK. Plugin architecture, planner system, and deep integration with Azure services.\n\n## ğŸ¯ What You'll Learn\n\n- Build agents using Semantic Kernel's plugin system\n- Use the planner for automatic task decomposition\n- Integrate with Azure AI services seamlessly\n- Create skills and functions for agent capabilities\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Unit Testing Agents","description":"Mock LLM responses and test agent behavior deterministically","slug":"ai-agents-engineering/05-testing-evaluation/01-unit-testing-agents","icon":"check-square","body":"# Unit Testing Agents\n\nMock LLM responses, test tool execution deterministically, and verify agent behavior without burning API credits on every test run.\n\n## ğŸ¯ What You'll Learn\n\n- Mock LLM responses for deterministic testing\n- Test tool execution in isolation\n- Verify agent decision-making logic\n- Build fast, cheap tests that run without API calls\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Evals","description":"Build evaluation suites that measure accuracy, quality, and regression over time","slug":"ai-agents-engineering/05-testing-evaluation/02-evals","icon":"bar-chart","body":"# Evals\n\nBuild evaluation suites that measure accuracy, quality, and regression over time. LLM-as-judge, golden datasets, and automated scoring pipelines.\n\n## ğŸ¯ What You'll Learn\n\n- Design evaluation datasets with golden examples\n- Implement LLM-as-judge scoring patterns\n- Build automated regression testing pipelines\n- Measure quality metrics that matter for your use case\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Tracing & Debugging","description":"Trace every LLM call, tool invocation, and decision point","slug":"ai-agents-engineering/05-testing-evaluation/03-tracing-debugging","icon":"search","body":"# Tracing & Debugging\n\nTrace every LLM call, tool invocation, and decision point. When your agent does something unexpected, you need to know exactly why.\n\n## ğŸ¯ What You'll Learn\n\n- Instrument agent code for comprehensive tracing\n- Debug complex multi-step agent failures\n- Visualize execution flows and decision points\n- Use observability tools during development\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Red Teaming & Safety","description":"Adversarial testing for agents â€” prompt injection, jailbreaks, and guardrails","slug":"ai-agents-engineering/05-testing-evaluation/04-red-teaming-safety","icon":"shield-off","body":"# Red Teaming & Safety\n\nAdversarial testing for agents. Prompt injection, jailbreaks, tool misuse, and building guardrails that hold up under attack.\n\n## ğŸ¯ What You'll Learn\n\n- Test agents against prompt injection attacks\n- Identify jailbreak vulnerabilities and tool misuse\n- Build guardrails that detect and block malicious input\n- Design defense-in-depth strategies for production\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Deployment Strategies","description":"Containers, serverless, and scaling patterns for agents","slug":"ai-agents-engineering/06-production/02-deployment-strategies","icon":"upload-cloud","body":"# Deployment Strategies\n\nContainers, serverless, and scaling patterns. How to package and ship agents that handle variable load and long-running tasks.\n\n## ğŸ¯ What You'll Learn\n\n- Package agents in containers for consistent deployment\n- Choose between serverless and long-running deployments\n- Scale agents to handle variable traffic loads\n- Handle long-running tasks without timeouts\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"12-Factor Agents","description":"Principles for building production-grade agents","slug":"ai-agents-engineering/06-production/01-twelve-factor-agents","icon":"list","body":"# 12-Factor Agents\n\nPrinciples for building production-grade agents. Inspired by the 12-factor app methodology, adapted for the unique challenges of LLM-powered systems.\n\n## ğŸ¯ What You'll Learn\n\n- Apply 12-factor principles to agent architecture\n- Design agents for portability and scalability\n- Configure agents through environment, not code\n- Build production-ready agents from day one\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Monitoring & Observability","description":"Metrics, structured logging, and distributed tracing for production agents","slug":"ai-agents-engineering/06-production/03-monitoring-observability","icon":"activity","body":"# Monitoring & Observability\n\nMetrics, structured logging, and distributed tracing for production agents. Know when things break before your users tell you.\n\n## ğŸ¯ What You'll Learn\n\n- Instrument agents with meaningful metrics\n- Implement structured logging for agent actions\n- Set up distributed tracing across agent calls\n- Build dashboards and alerts for production health\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Cost Optimization","description":"Token budgets, caching strategies, and model routing for cost control","slug":"ai-agents-engineering/06-production/04-cost-optimization","icon":"dollar-sign","body":"# Cost Optimization\n\nToken budgets, caching strategies, model routing, and knowing when a smaller model is the right call. Keep costs predictable as usage grows.\n\n## ğŸ¯ What You'll Learn\n\n- Set and enforce token budgets per request\n- Implement caching to reduce redundant API calls\n- Route requests to cheaper models when appropriate\n- Track and forecast costs as usage scales\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."},{"title":"Security & Guardrails","description":"Authentication, sandboxing, and prompt injection defense","slug":"ai-agents-engineering/06-production/05-security-guardrails","icon":"lock","body":"# Security & Guardrails\n\nAuthentication, sandboxing, prompt injection defense, and tool-use permissions. Build agents that are safe to expose to untrusted input.\n\n## ğŸ¯ What You'll Learn\n\n- Implement authentication and authorization for agent access\n- Sandbox tool execution to limit blast radius\n- Defend against prompt injection attacks\n- Design permission systems for tool-use safety\n\n> ğŸš§ **Coming soon** â€” [Subscribe to our Substack](https://agenticloopsai.substack.com) or â­ï¸ star the repo to get notified when this tutorial drops."}]